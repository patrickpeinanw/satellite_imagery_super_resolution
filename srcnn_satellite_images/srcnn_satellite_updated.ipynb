{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132264cb-c096-4d9c-8d4f-c0274115bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = 'True'\n",
    "import re \n",
    "from scipy import ndimage, misc \n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.transform import resize, rescale\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "import cv2\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense ,Conv2D,MaxPooling2D ,Dropout\n",
    "from tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Verify that TensorFlow can access the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ed809-17c9-4d44-afa7-d6007cfa53fb",
   "metadata": {},
   "source": [
    "### Load Raw Data\n",
    "\n",
    "read low resolution images and high resolution images into RGB values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adc10f-c0b8-4c7a-848c-adf6bdf75580",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_dataset_path = 'dataset/hr_dataset'\n",
    "lr_dataset_path = 'dataset/lr_dataset'\n",
    "hr_data = [d for d in os.listdir(hr_dataset_path) if os.path.isdir(os.path.join(lr_dataset_path, d))]\n",
    "lr_data = [d for d in os.listdir(lr_dataset_path) if os.path.isdir(os.path.join(lr_dataset_path, d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c9fd9-9b3c-495f-b118-209928f04c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of folders in '{hr_dataset_path}': {len(hr_data)}\")\n",
    "print(f\"Number of folders in '{lr_dataset_path}': {len(lr_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5d6a4-a4bb-4cd4-a244-5f9eb0b6274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_lr_images(aoi_base_name, num_revisits):\n",
    "#     \"\"\"\n",
    "#     Load low-resolution images from the dataset using rasterio.\n",
    "\n",
    "#     Args:\n",
    "#     - aoi_base_name: Base name of the AOI folder.\n",
    "#     - num_revisits: Number of low-resolution images needed.\n",
    "\n",
    "#     Returns:\n",
    "#     - List of loaded images.\n",
    "#     \"\"\"\n",
    "#     images = []\n",
    "#     for i in range(1, num_revisits+1):\n",
    "#         # lr_image_path = os.path.join('dataset/lr_dataset', aoi_base_name, 'L2A', f\"{aoi_base_name}-{i}-L2A_data.TIFF\")\n",
    "#         lr_image_path = os.path.join('dataset/lr_dataset', aoi_base_name, 'L1C', f\"{aoi_base_name}-{i}-L1C_data.TIFF\")\n",
    "#         if os.path.isfile(lr_image_path):\n",
    "#             try:\n",
    "#                 with rasterio.open(lr_image_path) as src:\n",
    "#                     image = src.read([4, 3, 2])  # Read RGB channels if available\n",
    "#                     image = np.moveaxis(image, 0, -1)  # Convert to HWC format\n",
    "#                     images.append(image)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Warning: Failed to read image {lr_image_path} with error {e}\")\n",
    "#         else:\n",
    "#             print(f\"Warning: Low-resolution image path {lr_image_path} does not exist\")\n",
    "#     return images\n",
    "\n",
    "def load_hr_images(aoi):\n",
    "    \"\"\"\n",
    "    Load high-resolution images from the dataset.\n",
    "\n",
    "    Args:\n",
    "    - aoi: Name of the AOI folder.\n",
    "\n",
    "    Returns:\n",
    "    - List of loaded images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    hr_image_path = os.path.join('dataset/hr_dataset', aoi, f\"{aoi}_ps.TIFF\")\n",
    "    if os.path.isfile(hr_image_path):\n",
    "        try:\n",
    "            with rasterio.open(hr_image_path) as src:\n",
    "                image = src.read([1, 2, 3])  # Read RGB channels if available\n",
    "                image = np.moveaxis(image, 0, -1)  # Convert to HWC format\n",
    "                images.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to read image {hr_image_path} with error {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: Low-resolution image path {hr_image_path} does not exist\")\n",
    "    return images\n",
    "\n",
    "def preprocess_image(image, target_size):\n",
    "    \"\"\"\n",
    "    Preprocess the image for SRCNN.\n",
    "\n",
    "    Args:\n",
    "    - image: Input image.\n",
    "    - target_size: Tuple of target size (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - Preprocessed image.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(image, target_size)\n",
    "    if np.max(image) != 0:\n",
    "        image = image / np.max(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_aois(aoi_names, target_size_hr, target_size_lr, num_revisits):\n",
    "    \"\"\"\n",
    "    Load and preprocess images for multiple AOIs.\n",
    "\n",
    "    Args:\n",
    "    - aoi_names: List of AOI base names.\n",
    "    - target_size_hr: Tuple of target size (width, height) for high-resolution images.\n",
    "    - target_size_lr: Tuple of target size (width, height) for low-resolution images.\n",
    "    - num_revisits: Number of low-resolution images needed.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary with AOI names as keys and tuple of (LR images, HR images) as values.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for aoi_base_name in aoi_names:\n",
    "        # print(f\"Processing AOI: {aoi_base_name}\")\n",
    "        # lr_images = load_lr_images(aoi_base_name, num_revisits)\n",
    "        hr_images = load_hr_images(aoi_base_name)\n",
    "\n",
    "        # Preprocess images\n",
    "        # lr_images = [preprocess_image(img, target_size_lr) for img in lr_images]\n",
    "        hr_images = [preprocess_image(img, target_size_hr) for img in hr_images]\n",
    "\n",
    "        # compress hr_images at scale of 5 to generate low res images\n",
    "        lr_images = []\n",
    "        for img in hr_images:\n",
    "            lr_images.append(cv2.resize(img, target_size_lr, interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        lr_images = np.array(lr_images)\n",
    "        hr_images = np.array(hr_images)\n",
    "        \n",
    "        data[aoi_base_name] = (lr_images, hr_images)\n",
    "        #print(f\"Low-resolution images shape for {aoi_base_name}: {lr_images.shape}\")\n",
    "        # print(f\"High-resolution images shape for {aoi_base_name}: {hr_images.shape}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4d44c-0d69-494a-9242-38efbc86500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "aoi_names = ['Amnesty POI-1-1-1', 'Amnesty POI-1-1-2'] # list of selected AOIs\n",
    "target_size_hr = (500, 500)  # assuming the target size for SRCNN is (500, 500)\n",
    "target_size_lr = (100, 100)\n",
    "num_revisits = 1 # 1-16\n",
    "\n",
    "aois_data = process_aois(aoi_names, target_size_hr, target_size_lr, num_revisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748941b-3078-422e-a9a0-d9c355e2b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "aois_data['Amnesty POI-1-1-1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc043a-3bff-417b-b5e1-b6c2216d941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aois_data['Amnesty POI-1-1-1'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49d714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aois_data['Amnesty POI-1-1-1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e686a-0b97-48ba-8a37-7f1d409d5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(aois_data['Amnesty POI-1-1-2'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedfba2-73ce-489c-b046-3f5e9a4dad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(aois_data['Amnesty POI-1-1-2'][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4f732-1742-4838-987e-528ce6e43590",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"dataset/metadata.csv\")\n",
    "metadata.rename(columns={metadata.columns[0]: 'aoi_name'}, inplace=True)\n",
    "metadata.drop_duplicates(subset=['aoi_name'], keep='first', inplace=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = metadata[(metadata['aoi_name'].str.contains('Landcover')) & (metadata['cloud_cover'] < 0.05)]\n",
    "len(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f83468",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = df_select['IPCC Class'].value_counts()\n",
    "\n",
    "# Plot the frequencies as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts.plot(kind='bar')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Frequency of Each Category in Your Column')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65957ce-b1a3-49ec-ba92-9ee00b1984a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_folders = []\n",
    "aoi_names_set = set(df_select['aoi_name'])\n",
    "\n",
    "# Loop over the directories in lr_dataset\n",
    "for folder_name in os.listdir(lr_dataset_path):\n",
    "    if folder_name in aoi_names_set:\n",
    "        landcover_folders.append(folder_name)\n",
    "    # Stop when 1000 folders have been added\n",
    "    if len(landcover_folders) >= 1000:\n",
    "        break\n",
    "\n",
    "#print(landcover_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e79d4-a529-4e8a-bce4-a65d7e80eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale the low-resolution images\n",
    "target_size_hr = (500, 500)  # assuming the target size for SRCNN is (500, 500)\n",
    "target_size_lr = (100, 100)\n",
    "sample_images = process_aois(landcover_folders, target_size_hr, target_size_lr, num_revisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb672fe0-d8d3-49af-a736-df01d526557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the loaded images in the dataset\n",
    "for i in range(20):\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Low Resolution Image', color = 'red', fontsize = 20)\n",
    "    plt.imshow(sample_images[landcover_folders[i]][0][0])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('High Resolution Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(sample_images[landcover_folders[i]][1][0])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac764a-dfd8-422e-8eea-71975b87f780",
   "metadata": {},
   "source": [
    "### Prepare Train, Test, and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all high-res and low-res images from sample_images\n",
    "all_high_images = []\n",
    "all_low_images = []\n",
    "\n",
    "for aoi_name in sample_images:\n",
    "    all_low_images.extend(sample_images[aoi_name][0])  # Low-resolution images\n",
    "    all_high_images.extend(sample_images[aoi_name][1])  # High-resolution images\n",
    "\n",
    "# upscale the 100 x 100 low resolution image to 500 x 500 using bicubic interpolation\n",
    "for i in range(len(all_low_images)):\n",
    "    upscaled_img = cv2.resize(all_low_images[i], (500, 500), interpolation=cv2.INTER_CUBIC)\n",
    "    all_low_images[i] = upscaled_img\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_high_images = np.array(all_high_images)\n",
    "all_low_images = np.array(all_low_images)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_high_image = all_high_images[:800]\n",
    "train_low_image = all_low_images[:800]\n",
    "\n",
    "validation_high_image = all_high_images[800:900]\n",
    "validation_low_image = all_low_images[800:900]\n",
    "\n",
    "test_high_image = all_high_images[900:]\n",
    "test_low_image = all_low_images[900:]\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Shape of training images:\", train_high_image.shape)\n",
    "print(\"Shape of test images:\", test_high_image.shape)\n",
    "print(\"Shape of validation images:\", validation_high_image.shape)\n",
    "\n",
    "print(\"Shape of training low images:\", train_low_image.shape)\n",
    "print(\"Shape of test low images:\", test_low_image.shape)\n",
    "print(\"Shape of validation low images:\", validation_low_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3829fcc-82f2-4807-8bcd-20c2d664c0b2",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406fdf1-5b02-4878-bd7e-c4c2b5ce7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62299810-24d2-494e-bbaa-e3cc2d0221ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRCNN = Sequential([\n",
    "    Conv2D(128, (9, 9), padding='same', input_shape=(500, 500, 3)),\n",
    "    Activation('relu'),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "\n",
    "    Conv2D(32, (1, 1), padding='same'),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Conv2D(3, (5, 5), padding='same'),\n",
    "    Activation('relu')\n",
    "])\n",
    "\n",
    "def pixel_mse_loss(x,y):\n",
    "    return tf.reduce_mean( (x - y) ** 2 )\n",
    "\n",
    "SRCNN.compile(optimizer=tf.keras.optimizers.legacy.Adam(0.001),loss=pixel_mse_loss)\n",
    "# SRCNN.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=pixel_mse_loss)\n",
    "\n",
    "SRCNN.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint('srcnn_model_checkpoint.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08722451-d6f0-460e-b647-1b99213358f1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5e9db-87c2-455c-bf32-ff9335cb77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SRCNN.fit(\n",
    "    train_low_image,\n",
    "    train_high_image,\n",
    "    epochs = 100,\n",
    "    batch_size = 10,\n",
    "    validation_data = (validation_low_image,validation_high_image),\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced792d-27cd-4908-b685-244c887c021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights\n",
    "SRCNN.save_weights('srcnn_weights_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c03542-6cf7-4c14-95d7-f073f9e50fe0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Define Image Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bca87-129a-488a-af51-f0aabdce54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "\n",
    "def psnr(target, ref):\n",
    "    \"\"\"\n",
    "    Compute the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "\n",
    "    PSNR is used to measure the quality of reconstruction of lossy compression codecs.\n",
    "    The signal is the original data, and the noise is the error introduced by compression.\n",
    "\n",
    "    Args:\n",
    "        target (numpy.ndarray): The target (reference) image.\n",
    "        ref (numpy.ndarray): The reference image to compare against.\n",
    "\n",
    "    Returns:\n",
    "        float: The PSNR value in decibels (dB).\n",
    "\n",
    "    \"\"\"\n",
    "    target_data = target.astype(float)\n",
    "    ref_data = ref.astype(float)\n",
    "    \n",
    "    diff = ref_data-target_data\n",
    "    diff = diff.flatten('C') # need ot flatten so computations can be done\n",
    "    \n",
    "    rmse = math.sqrt(np.mean(diff**2.))\n",
    "    \n",
    "    return 20 * math.log10(255./rmse)\n",
    "\n",
    "\n",
    "def mse(target,ref):\n",
    "    \"\"\"\n",
    "    \n",
    "    Compute the Mean Squared Error (MSE) between two images.\n",
    "\n",
    "    MSE is a risk function corresponding to the expected value of the squared error loss.\n",
    "    It is used to measure the average of the squares of the errors, i.e., the average squared difference\n",
    "    between the estimated values and the actual value.\n",
    "\n",
    "    Args:\n",
    "        target (numpy.ndarray): The target (reference) image.\n",
    "        ref (numpy.ndarray): The reference image to compare against.\n",
    "\n",
    "    Returns:\n",
    "        float: The MSE value.\n",
    "\n",
    "    \"\"\"\n",
    "    err=np.sum((target.astype('float')-ref.astype('float'))**2)\n",
    "    err=err/float(target.shape[0]*target.shape[1]) # divided by total number of pixels\n",
    "    \n",
    "    return err\n",
    "\n",
    "\n",
    "def compare_images(target,ref):\n",
    "    \"\"\"\n",
    "    Compute the PSNR, MSE, and SSIM between two images.\n",
    "\n",
    "    This function combines three image quality metrics:\n",
    "    - Peak Signal-to-Noise Ratio (PSNR)\n",
    "    - Mean Squared Error (MSE)\n",
    "    - Structural Similarity Index (SSIM)\n",
    "\n",
    "    Args:\n",
    "        target (numpy.ndarray): The target (reference) image.\n",
    "        ref (numpy.ndarray): The reference image to compare against.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the PSNR, MSE, and SSIM values, respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    # _target = target * 255\n",
    "    # _ref = ref * 255\n",
    "    scores=[\n",
    "        psnr(target, ref),\n",
    "        mse(target, ref),\n",
    "        ssim(target, ref, win_size=11, channel_axis=2, data_range=255)\n",
    "    ]\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4665d4-2864-4f4a-91a8-0279e0155710",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd958a01-5102-47d4-acec-5cf8809da750",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image = SRCNN.predict(test_low_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40593c9a-9aa7-46f9-963b-9d90e0d0f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process predictions\n",
    "pred_image *= 255\n",
    "pred_image = np.clip(pred_image, 0, 255)\n",
    "pred_image = pred_image.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b14092-aa3e-4c8f-8247-dcb69443baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold scores for all images\n",
    "pred_scores = []\n",
    "original_scores = []\n",
    "\n",
    "# Iterate over each image to compute the quality metrics\n",
    "for i in range(len(test_low_image)):\n",
    "    pred = pred_image[i]\n",
    "    original = test_low_image[i] * 255\n",
    "    truth = test_high_image[i] * 255\n",
    "    original = original.astype(np.uint8)\n",
    "    truth = truth.astype(np.uint8)\n",
    "    # original = test_low_image[i]\n",
    "    # truth = test_high_image[i]\n",
    "\n",
    "    pred_scores.append(compare_images(pred, truth))\n",
    "    original_scores.append(compare_images(original, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802a844-9064-425e-bae7-ceafb975f587",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f156e9-4ee5-48e2-8c27-b0872f06883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_low_image)):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    \n",
    "    axs[0].imshow(test_low_image[i])\n",
    "    axs[0].set_title('Upscaled')\n",
    "    axs[0].set(xlabel = 'PSNR: {}\\nMSE: {} \\nSSIM: {}'.format(original_scores[i][0], original_scores[i][1], original_scores[i][2]))\n",
    "\n",
    "    axs[1].imshow(pred_image[i])\n",
    "    axs[1].set_title('Generated by SRCNN')\n",
    "    axs[1].set(xlabel = 'PSNR: {}\\nMSE: {} \\nSSIM: {}'.format(pred_scores[i][0], pred_scores[i][1], pred_scores[i][2]))\n",
    "\n",
    "    axs[2].imshow(test_high_image[i])\n",
    "    axs[2].set_title('Target')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aee49a-c783-4037-b1a1-412659c377da",
   "metadata": {},
   "source": [
    "### Effectiveness\n",
    "Compare the PSNR/MSE/SSIM of the original low-resolution image and the processed images generated by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514043ff-cc0a-40ca-9200-7f5f46cac1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PSNR, MSE, and SSIM for plotting\n",
    "original_psnr = [score[0] for score in original_scores]\n",
    "original_mse = [score[1] for score in original_scores]\n",
    "original_ssim = [score[2] for score in original_scores]\n",
    "pred_psnr = [score[0] for score in pred_scores]\n",
    "pred_mse = [score[1] for score in pred_scores]\n",
    "pred_ssim = [score[2] for score in pred_scores]\n",
    "\n",
    "# Calculate percentage increase\n",
    "psnr_increase = [(p - o) / o * 100 for p, o in zip(pred_psnr, original_psnr)]\n",
    "mse_increase = [(p - o) / o * 100 for p, o in zip(pred_mse, original_mse)]\n",
    "ssim_increase = [(p - o) / o * 100 for p, o in zip(pred_ssim, original_ssim)]\n",
    "\n",
    "# Number of test images\n",
    "num_images = len(original_scores)\n",
    "image_indices = range(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfb7db-d04a-4925-907a-e6984ec7c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentage increase for PSNR\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(image_indices, psnr_increase, color='blue')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('Percentage Increase (%)')\n",
    "plt.title('Percentage Change in PSNR')\n",
    "plt.show()\n",
    "# Plot PSNR comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(num_images), original_psnr, label='Original Low-Res PSNR', marker='o')\n",
    "plt.plot(range(num_images), pred_psnr, label='Generated High-Res PSNR', marker='x')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713bda4-5185-49e8-9506-544d4be158f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentage increase for MSE\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(image_indices, mse_increase, color='green')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('Percentage Increase (%)')\n",
    "plt.title('Percentage Change in MSE')\n",
    "plt.show()\n",
    "# Plot MSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(num_images), original_mse, label='Original Low-Res MSE', marker='o')\n",
    "plt.plot(range(num_images), pred_mse, label='Generated High-Res MSE', marker='x')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166340d-5d55-4fc9-ba11-1a16eed560ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentage increase for SSIM\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(image_indices, ssim_increase, color='purple')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('Percentage Increase (%)')\n",
    "plt.title('Percentage Change in SSIM')\n",
    "plt.show()\n",
    "# Plot SSIM comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(num_images), original_ssim, label='Original Low-Res SSIM', marker='o')\n",
    "plt.plot(range(num_images), pred_ssim, label='Generated High-Res SSIM', marker='x')\n",
    "plt.xlabel('Test Image Index')\n",
    "plt.ylabel('SSIM')\n",
    "plt.title('SSIM Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf006f52-1a6f-489e-9776-043ca4618c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
